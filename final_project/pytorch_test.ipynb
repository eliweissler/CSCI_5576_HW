{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA AVALIABLE: True\n",
      "DEVICE: NVIDIA RTX A4500\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import qutip as qt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"CUDA AVALIABLE:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"DEVICE:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Custom Imports\n",
    "from data_gen import read_data, dset_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data.hdf5\"\n",
    "complex_type = torch.complex64\n",
    "states, H = read_data(file, dim=2, label=\"train\", i_start=0, i_end=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8918+0.j,  0.0000+0.j],\n",
       "         [ 0.0000+0.j, -0.7244+0.j]], device='cuda:0'),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.tensor(H[0, 0], dtype=complex_type).to(device)\n",
    "d, d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a Model with Complex Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'complex_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m       x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense2(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m       \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m model \u001b[39m=\u001b[39m Net()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n",
      "\u001b[1;32m/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39msuper\u001b[39m(Net, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mFlatten(start_dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, end_dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense1\u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m   nn\u001b[39m.\u001b[39mLinear(\u001b[39m4\u001b[39m, \u001b[39m2\u001b[39m, dtype\u001b[39m=\u001b[39mcomplex_type),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m   nn\u001b[39m.\u001b[39mSigmoid()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m   nn\u001b[39m.\u001b[39mLinear(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mcomplex_type),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m   nn\u001b[39m.\u001b[39mSigmoid()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'complex_type' is not defined"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(Net, self).__init__()\n",
    "      self.flatten = nn.Flatten(start_dim=0, end_dim=-1)\n",
    "      self.dense1= nn.Sequential(\n",
    "        nn.Linear(4, 2, dtype=complex_type),\n",
    "        nn.Sigmoid()\n",
    "      )\n",
    "      self.dense2 = nn.Sequential(\n",
    "        nn.Linear(2, 1, dtype=complex_type),\n",
    "        nn.Sigmoid()\n",
    "      )\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, x):\n",
    "\n",
    "      x = self.flatten(x)\n",
    "      print(x)\n",
    "      x = self.dense1(x)\n",
    "      x = self.dense2(x)\n",
    "\n",
    "      return x\n",
    "\n",
    "model = Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8918+0.j,  0.0000+0.j,  0.0000+0.j, -0.7244+0.j], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.6411+0.1663j], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a PyTorch Data Loader for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeStepData(Dataset):\n",
    "    def __init__(self, hfile, dim, label, complex_type=torch.complex128, preload=True, device=None):\n",
    "        self.hfile = hfile\n",
    "        self.dim = dim\n",
    "        self.shape = dset_size(hfile, dim, label)\n",
    "        self.label = label\n",
    "        self.complex_type = complex_type\n",
    "\n",
    "        self.preload=preload\n",
    "        if preload:\n",
    "            self.data = read_data(self.hfile, self.dim, self.label, 0, self.shape[0]+1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.shape[0]*(self.shape[1]-1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       entry_idx = int(idx/(self.shape[1]-1))\n",
    "       time_idx = idx - entry_idx*(self.shape[1]-1)\n",
    "       if self.preload:\n",
    "            states, Hs = self.data[0][entry_idx:entry_idx+1], self.data[1][entry_idx:entry_idx+1]\n",
    "       else:\n",
    "            states, Hs = read_data(self.hfile, self.dim, self.label, entry_idx, entry_idx+1)\n",
    "       state = states[0, time_idx]\n",
    "       H = Hs[0, time_idx]\n",
    "       next_state = states[0, time_idx+1]\n",
    "       \n",
    "       input_tensor = torch.tensor(np.concatenate((state.flatten(), H.flatten())), dtype=self.complex_type)\n",
    "       output_tensor = torch.tensor(next_state.flatten(), dtype=self.complex_type)\n",
    "\n",
    "       if device is not None:\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        output_tensor = output_tensor.to(device)\n",
    "\n",
    "       return input_tensor, output_tensor\n",
    "\n",
    "class seqData(Dataset):\n",
    "    def __init__(self, hfile, dim, label):\n",
    "        self.hfile = hfile\n",
    "        self.dim = dim\n",
    "        self.shape = dset_size(hfile, dim, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       states, Hs = read_data(self.hfile, self.dim, self.label, idx, idx+1)\n",
    "       return states, idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfile = \"data.hdf5\"\n",
    "dim = 2\n",
    "batch_size = 100000\n",
    "train_data = timeStepData(hfile, dim, \"train\", preload=True, device=device)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_data = timeStepData(hfile, dim, \"test\", preload=True, device=device)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Next Step Predicting Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepPredNet(nn.Module):\n",
    "    def __init__(self, dim, complex_type=torch.complex128):\n",
    "      super(StepPredNet, self).__init__()\n",
    "      self.dim = dim\n",
    "      self.complex_type = complex_type\n",
    "      self.dense1= nn.Sequential(\n",
    "        nn.Linear(dim + dim**2, 4*dim, dtype=self.complex_type, bias=True),\n",
    "        # nn.Sigmoid()\n",
    "      )\n",
    "      self.dense2 = nn.Sequential(\n",
    "        nn.Linear(4*dim, 2*dim, dtype=self.complex_type, bias=True),\n",
    "        # nn.Sigmoid()\n",
    "      )\n",
    "      self.dense3 = nn.Sequential(\n",
    "        nn.Linear(2*dim, dim, dtype=self.complex_type, bias=True),\n",
    "        # nn.Sigmoid()\n",
    "      )\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, x):\n",
    "\n",
    "      x = self.dense1(x)\n",
    "      x = self.dense2(x)\n",
    "      x = self.dense3(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StepPredNet(\n",
      "  (dense1): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=8, bias=False)\n",
      "  )\n",
      "  (dense2): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=4, bias=True)\n",
      "  )\n",
      "  (dense3): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = StepPredNet(dim=2).to(device)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "print(model)\n",
    "# Optimizers specified in the torch.optim package\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer, training_loader, loss_fn):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    batch_size = training_loader.batch_size\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in tqdm(enumerate(training_loader), total=len(training_loader)):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % batch_size == batch_size-1:\n",
    "            last_loss = running_loss / batch_size # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            # tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            # running_loss = 0.\n",
    "\n",
    "    return running_loss/len(training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6650391754818471 valid 0.6542452523375063\n",
      "EPOCH 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6610035742013255 valid 0.6502504879807097\n",
      "EPOCH 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6569705569704661 valid 0.6462638496670552\n",
      "EPOCH 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6529372148672505 valid 0.6422813170887438\n",
      "EPOCH 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6489024581984404 valid 0.6382995815789931\n",
      "EPOCH 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6448659266977574 valid 0.6343171076525231\n",
      "EPOCH 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6408272821346266 valid 0.6303328689945346\n",
      "EPOCH 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6367860502357895 valid 0.6263461256014362\n",
      "EPOCH 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6327417210033942 valid 0.6223564885083935\n",
      "EPOCH 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6286937350979787 valid 0.618363725122444\n",
      "EPOCH 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.624641540673816 valid 0.6143672302484458\n",
      "EPOCH 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6205846241955646 valid 0.6103665830761004\n",
      "EPOCH 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6165223097902854 valid 0.6063613435308675\n",
      "EPOCH 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.612453946037005 valid 0.6023509299297317\n",
      "EPOCH 15:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6083788563476688 valid 0.5983343684464668\n",
      "EPOCH 16:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6042963297586603 valid 0.5943108054697749\n",
      "EPOCH 17:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6002055512989577 valid 0.5902794002873635\n",
      "EPOCH 18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5961057469629061 valid 0.5862392411702861\n",
      "EPOCH 19:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5919961837017853 valid 0.5821893585726189\n",
      "EPOCH 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5878759983329388 valid 0.5781287403922223\n",
      "EPOCH 21:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.583744306536354 valid 0.5740564176135001\n",
      "EPOCH 22:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5796002217313129 valid 0.5699713966865034\n",
      "EPOCH 23:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5754427466156364 valid 0.5658726396146958\n",
      "EPOCH 24:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5712709648429822 valid 0.5617590657589935\n",
      "EPOCH 25:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5670838701286233 valid 0.5576295656489663\n",
      "EPOCH 26:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5628801957370566 valid 0.5534830432448451\n",
      "EPOCH 27:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5586587381129243 valid 0.5493184117816676\n",
      "EPOCH 28:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.5544183604593178 valid 0.5451345528959055\n",
      "EPOCH 29:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m avg_loss \u001b[39m=\u001b[39m train_one_epoch(epoch_number, writer, training_loader\u001b[39m=\u001b[39;49mtraining_loader, loss_fn\u001b[39m=\u001b[39;49mloss_fn)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m running_vloss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Set the model to evaluation mode, disabling dropout and using population\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# statistics for batch normalization.\u001b[39;00m\n",
      "\u001b[1;32m/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb Cell 15\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m batch_size \u001b[39m=\u001b[39m training_loader\u001b[39m.\u001b[39mbatch_size\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Here, we use enumerate(training_loader) instead of\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# iter(training_loader) so that we can track the batch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# index and do some intra-epoch reporting\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(training_loader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(training_loader)):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Every data instance is an input + label pair\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Zero your gradients for every batch!\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m H \u001b[39m=\u001b[39m Hs[\u001b[39m0\u001b[39m, time_idx]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m next_state \u001b[39m=\u001b[39m states[\u001b[39m0\u001b[39m, time_idx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m input_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(np\u001b[39m.\u001b[39;49mconcatenate((state\u001b[39m.\u001b[39;49mflatten(), H\u001b[39m.\u001b[39;49mflatten())), dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomplex_type)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m output_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(next_state\u001b[39m.\u001b[39mflatten(), dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomplex_type)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bewdesktop/home/eweissler/src/neural_networks_hw/final_project/pytorch_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "writer = SummaryWriter('runs/timestep_solver')\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "training_loader = train_dataloader\n",
    "validation_loader = test_dataloader\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer, training_loader=training_loader, loss_fn=loss_fn)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    train_loss.append(avg_loss)\n",
    "    val_loss.append(avg_vloss)\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.6102+0.6320j,  0.3589+0.3154j, -0.7519+0.0000j,  0.0000+0.0000j,\n",
       "           0.0000+0.0000j,  0.1941+0.0000j],\n",
       "         [-0.0525+0.8346j,  0.2350-0.4954j, -0.3099+0.0000j,  0.0000+0.0000j,\n",
       "           0.0000+0.0000j, -0.8093+0.0000j],\n",
       "         [-0.8862+0.0178j,  0.2164-0.4094j,  0.5445+0.0000j, -0.2585+0.2074j,\n",
       "          -0.2585-0.2074j, -0.0779+0.0000j],\n",
       "         ...,\n",
       "         [ 0.1643+0.8408j,  0.2744+0.4368j,  0.4394+0.0000j,  0.0695+0.0402j,\n",
       "           0.0695-0.0402j, -0.1928+0.0000j],\n",
       "         [-0.3953+0.4877j, -0.0997-0.7720j, -0.1093+0.0000j,  0.0000+0.0000j,\n",
       "           0.0000+0.0000j,  0.5864+0.0000j],\n",
       "         [ 0.8998-0.0674j,  0.4275-0.0558j,  0.3352+0.0000j, -0.1153-0.2835j,\n",
       "          -0.1153+0.2835j,  0.2473+0.0000j]], device='cuda:0',\n",
       "        dtype=torch.complex128),\n",
       " tensor([[-0.6570+0.5832j,  0.3646+0.3088j],\n",
       "         [-0.0768+0.8327j,  0.2752-0.4743j],\n",
       "         [-0.8681+0.0627j,  0.2368-0.4318j],\n",
       "         ...,\n",
       "         [ 0.2050+0.8325j,  0.2708+0.4376j],\n",
       "         [-0.4007+0.4833j, -0.1449-0.7648j],\n",
       "         [ 0.8847-0.0897j,  0.4536-0.0582j]], dtype=torch.complex128)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(training_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01567732+0.14814522j, -0.97666745-0.15068713j])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(psi_next.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0162+0.1483j, -0.9769-0.1531j, -0.2388+0.0000j,  0.0000+0.0000j,\n",
      "         0.0000+0.0000j, -0.6597+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0157+0.1481j, -0.9767-0.1507j], dtype=torch.complex128)\n",
      "tensor([ 0.0157+0.1481j, -0.9767-0.1507j, -0.2388+0.0000j,  0.0019+0.0003j,\n",
      "         0.0019-0.0003j, -0.6580+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0151+0.1480j, -0.9764-0.1482j], dtype=torch.complex128)\n",
      "tensor([ 0.0151+0.1480j, -0.9764-0.1482j, -0.2388+0.0000j,  0.0038+0.0007j,\n",
      "         0.0038-0.0007j, -0.6563+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0145+0.1478j, -0.9762-0.1457j], dtype=torch.complex128)\n",
      "tensor([ 0.0145+0.1478j, -0.9762-0.1457j, -0.2388+0.0000j,  0.0055+0.0010j,\n",
      "         0.0055-0.0010j, -0.6548+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0139+0.1477j, -0.9760-0.1432j], dtype=torch.complex128)\n",
      "tensor([ 0.0139+0.1477j, -0.9760-0.1432j, -0.2388+0.0000j,  0.0072+0.0013j,\n",
      "         0.0072-0.0013j, -0.6533+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0133+0.1475j, -0.9757-0.1407j], dtype=torch.complex128)\n",
      "tensor([ 0.0133+0.1475j, -0.9757-0.1407j, -0.2388+0.0000j,  0.0087+0.0015j,\n",
      "         0.0087-0.0015j, -0.6519+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0127+0.1474j, -0.9755-0.1382j], dtype=torch.complex128)\n",
      "tensor([ 0.0127+0.1474j, -0.9755-0.1382j, -0.2388+0.0000j,  0.0101+0.0018j,\n",
      "         0.0101-0.0018j, -0.6507+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0120+0.1473j, -0.9752-0.1357j], dtype=torch.complex128)\n",
      "tensor([ 0.0120+0.1473j, -0.9752-0.1357j, -0.2388+0.0000j,  0.0113+0.0020j,\n",
      "         0.0113-0.0020j, -0.6496+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0113+0.1471j, -0.9750-0.1331j], dtype=torch.complex128)\n",
      "tensor([ 0.0113+0.1471j, -0.9750-0.1331j, -0.2388+0.0000j,  0.0123+0.0022j,\n",
      "         0.0123-0.0022j, -0.6487+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0106+0.1470j, -0.9747-0.1306j], dtype=torch.complex128)\n",
      "tensor([ 0.0106+0.1470j, -0.9747-0.1306j, -0.2388+0.0000j,  0.0132+0.0023j,\n",
      "         0.0132-0.0023j, -0.6479+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0100+0.1468j, -0.9744-0.1280j], dtype=torch.complex128)\n",
      "tensor([ 0.0100+0.1468j, -0.9744-0.1280j, -0.2388+0.0000j,  0.0139+0.0024j,\n",
      "         0.0139-0.0024j, -0.6473+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0093+0.1467j, -0.9741-0.1254j], dtype=torch.complex128)\n",
      "tensor([ 0.0093+0.1467j, -0.9741-0.1254j, -0.2388+0.0000j,  0.0143+0.0025j,\n",
      "         0.0143-0.0025j, -0.6469+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0086+0.1465j, -0.9738-0.1229j], dtype=torch.complex128)\n",
      "tensor([ 0.0086+0.1465j, -0.9738-0.1229j, -0.2388+0.0000j,  0.0145+0.0026j,\n",
      "         0.0145-0.0026j, -0.6467+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0079+0.1464j, -0.9735-0.1203j], dtype=torch.complex128)\n",
      "tensor([ 0.0079+0.1464j, -0.9735-0.1203j, -0.2388+0.0000j,  0.0145+0.0025j,\n",
      "         0.0145-0.0025j, -0.6468+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0072+0.1462j, -0.9732-0.1177j], dtype=torch.complex128)\n",
      "tensor([ 0.0072+0.1462j, -0.9732-0.1177j, -0.2388+0.0000j,  0.0142+0.0025j,\n",
      "         0.0142-0.0025j, -0.6470+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0065+0.1461j, -0.9729-0.1152j], dtype=torch.complex128)\n",
      "tensor([ 0.0065+0.1461j, -0.9729-0.1152j, -0.2388+0.0000j,  0.0136+0.0024j,\n",
      "         0.0136-0.0024j, -0.6475+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0058+0.1460j, -0.9725-0.1126j], dtype=torch.complex128)\n",
      "tensor([ 0.0058+0.1460j, -0.9725-0.1126j, -0.2388+0.0000j,  0.0128+0.0022j,\n",
      "         0.0128-0.0022j, -0.6483+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0051+0.1458j, -0.9722-0.1101j], dtype=torch.complex128)\n",
      "tensor([ 0.0051+0.1458j, -0.9722-0.1101j, -0.2388+0.0000j,  0.0116+0.0020j,\n",
      "         0.0116-0.0020j, -0.6493+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0044+0.1457j, -0.9719-0.1075j], dtype=torch.complex128)\n",
      "tensor([ 0.0044+0.1457j, -0.9719-0.1075j, -0.2388+0.0000j,  0.0102+0.0018j,\n",
      "         0.0102-0.0018j, -0.6506+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0038+0.1455j, -0.9715-0.1050j], dtype=torch.complex128)\n",
      "tensor([ 0.0038+0.1455j, -0.9715-0.1050j, -0.2388+0.0000j,  0.0084+0.0015j,\n",
      "         0.0084-0.0015j, -0.6522+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0032+0.1454j, -0.9711-0.1025j], dtype=torch.complex128)\n",
      "tensor([ 0.0032+0.1454j, -0.9711-0.1025j, -0.2388+0.0000j,  0.0064+0.0011j,\n",
      "         0.0064-0.0011j, -0.6540+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0026+0.1452j, -0.9708-0.1000j], dtype=torch.complex128)\n",
      "tensor([ 0.0026+0.1452j, -0.9708-0.1000j, -0.2388+0.0000j,  0.0040+0.0007j,\n",
      "         0.0040-0.0007j, -0.6561+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0020+0.1451j, -0.9704-0.0976j], dtype=torch.complex128)\n",
      "tensor([ 0.0020+0.1451j, -0.9704-0.0976j, -0.2388+0.0000j,  0.0013+0.0002j,\n",
      "         0.0013-0.0002j, -0.6585+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0015+0.1449j, -0.9700-0.0952j], dtype=torch.complex128)\n",
      "tensor([ 0.0015+0.1449j, -0.9700-0.0952j, -0.2388+0.0000j, -0.0017-0.0003j,\n",
      "        -0.0017+0.0003j, -0.6612+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0010+0.1448j, -0.9697-0.0928j], dtype=torch.complex128)\n",
      "tensor([ 0.0010+0.1448j, -0.9697-0.0928j, -0.2388+0.0000j, -0.0050-0.0009j,\n",
      "        -0.0050+0.0009j, -0.6641+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 5.3691e-04+0.1446j, -9.6927e-01-0.0905j], dtype=torch.complex128)\n",
      "tensor([ 5.3691e-04+0.1446j, -9.6927e-01-0.0905j, -2.3878e-01+0.0000j,\n",
      "        -8.5669e-03-0.0015j, -8.5669e-03+0.0015j, -6.6730e-01+0.0000j],\n",
      "       device='cuda:0', dtype=torch.complex128)\n",
      "tensor([ 1.2680e-04+0.1444j, -9.6888e-01-0.0882j], dtype=torch.complex128)\n",
      "tensor([ 1.2680e-04+0.1444j, -9.6888e-01-0.0882j, -2.3878e-01+0.0000j,\n",
      "        -1.2454e-02-0.0022j, -1.2454e-02+0.0022j, -6.7076e-01+0.0000j],\n",
      "       device='cuda:0', dtype=torch.complex128)\n",
      "tensor([-2.3581e-04+0.1443j, -9.6848e-01-0.0859j], dtype=torch.complex128)\n",
      "tensor([-2.3581e-04+0.1443j, -9.6848e-01-0.0859j, -2.3878e-01+0.0000j,\n",
      "        -1.6617e-02-0.0029j, -1.6617e-02+0.0029j, -6.7446e-01+0.0000j],\n",
      "       device='cuda:0', dtype=torch.complex128)\n",
      "tensor([-5.4767e-04+0.1441j, -9.6808e-01-0.0837j], dtype=torch.complex128)\n",
      "tensor([-5.4767e-04+0.1441j, -9.6808e-01-0.0837j, -2.3878e-01+0.0000j,\n",
      "        -2.1042e-02-0.0037j, -2.1042e-02+0.0037j, -6.7840e-01+0.0000j],\n",
      "       device='cuda:0', dtype=torch.complex128)\n",
      "tensor([-8.0567e-04+0.1439j, -9.6767e-01-0.0815j], dtype=torch.complex128)\n",
      "tensor([-8.0567e-04+0.1439j, -9.6767e-01-0.0815j, -2.3878e-01+0.0000j,\n",
      "        -2.5711e-02-0.0045j, -2.5711e-02+0.0045j, -6.8256e-01+0.0000j],\n",
      "       device='cuda:0', dtype=torch.complex128)\n",
      "tensor([-0.0010+0.1438j, -0.9673-0.0794j], dtype=torch.complex128)\n",
      "tensor([-0.0010+0.1438j, -0.9673-0.0794j, -0.2388+0.0000j, -0.0306-0.0054j,\n",
      "        -0.0306+0.0054j, -0.6869+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([-0.0011+0.1436j, -0.9668-0.0773j], dtype=torch.complex128)\n",
      "tensor([-0.0011+0.1436j, -0.9668-0.0773j, -0.2388+0.0000j, -0.0357-0.0063j,\n",
      "        -0.0357+0.0063j, -0.6915+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([-0.0012+0.1434j, -0.9664-0.0753j], dtype=torch.complex128)\n",
      "tensor([-0.0012+0.1434j, -0.9664-0.0753j, -0.2388+0.0000j, -0.0410-0.0072j,\n",
      "        -0.0410+0.0072j, -0.6961+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([-0.0012+0.1432j, -0.9660-0.0733j], dtype=torch.complex128)\n",
      "tensor([-0.0012+0.1432j, -0.9660-0.0733j, -0.2388+0.0000j, -0.0464-0.0082j,\n",
      "        -0.0464+0.0082j, -0.7010+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([-0.0012+0.1431j, -0.9656-0.0714j], dtype=torch.complex128)\n",
      "tensor([-0.0012+0.1431j, -0.9656-0.0714j, -0.2388+0.0000j, -0.0519-0.0091j,\n",
      "        -0.0519+0.0091j, -0.7059+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([-0.0011+0.1429j, -0.9651-0.0696j], dtype=torch.complex128)\n",
      "tensor([-0.0011+0.1429j, -0.9651-0.0696j, -0.2388+0.0000j, -0.0576-0.0101j,\n",
      "        -0.0576+0.0101j, -0.7109+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([-8.9552e-04+0.1427j, -9.6471e-01-0.0678j], dtype=torch.complex128)\n",
      "tensor([-8.9552e-04+0.1427j, -9.6471e-01-0.0678j, -2.3878e-01+0.0000j,\n",
      "        -6.3279e-02-0.0111j, -6.3279e-02+0.0111j, -7.1601e-01+0.0000j],\n",
      "       device='cuda:0', dtype=torch.complex128)\n",
      "tensor([-6.4243e-04+0.1425j, -9.6428e-01-0.0661j], dtype=torch.complex128)\n",
      "tensor([-6.4243e-04+0.1425j, -9.6428e-01-0.0661j, -2.3878e-01+0.0000j,\n",
      "        -6.9006e-02-0.0121j, -6.9006e-02+0.0121j, -7.2111e-01+0.0000j],\n",
      "       device='cuda:0', dtype=torch.complex128)\n",
      "tensor([-3.2029e-04+0.1423j, -9.6384e-01-0.0645j], dtype=torch.complex128)\n",
      "tensor([-3.2029e-04+0.1423j, -9.6384e-01-0.0645j, -2.3878e-01+0.0000j,\n",
      "        -7.4727e-02-0.0132j, -7.4727e-02+0.0132j, -7.2621e-01+0.0000j],\n",
      "       device='cuda:0', dtype=torch.complex128)\n",
      "tensor([ 7.0788e-05+0.1421j, -9.6340e-01-0.0629j], dtype=torch.complex128)\n",
      "tensor([ 7.0788e-05+0.1421j, -9.6340e-01-0.0629j, -2.3878e-01+0.0000j,\n",
      "        -8.0408e-02-0.0141j, -8.0408e-02+0.0141j, -7.3126e-01+0.0000j],\n",
      "       device='cuda:0', dtype=torch.complex128)\n",
      "tensor([ 5.3028e-04+0.1419j, -9.6296e-01-0.0613j], dtype=torch.complex128)\n",
      "tensor([ 5.3028e-04+0.1419j, -9.6296e-01-0.0613j, -2.3878e-01+0.0000j,\n",
      "        -8.6013e-02-0.0151j, -8.6013e-02+0.0151j, -7.3626e-01+0.0000j],\n",
      "       device='cuda:0', dtype=torch.complex128)\n",
      "tensor([ 0.0011+0.1417j, -0.9625-0.0598j], dtype=torch.complex128)\n",
      "tensor([ 0.0011+0.1417j, -0.9625-0.0598j, -0.2388+0.0000j, -0.0915-0.0161j,\n",
      "        -0.0915+0.0161j, -0.7411+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0017+0.1415j, -0.9621-0.0584j], dtype=torch.complex128)\n",
      "tensor([ 0.0017+0.1415j, -0.9621-0.0584j, -0.2388+0.0000j, -0.0969-0.0170j,\n",
      "        -0.0969+0.0170j, -0.7459+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0023+0.1413j, -0.9616-0.0571j], dtype=torch.complex128)\n",
      "tensor([ 0.0023+0.1413j, -0.9616-0.0571j, -0.2388+0.0000j, -0.1020-0.0180j,\n",
      "        -0.1020+0.0180j, -0.7505+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0030+0.1411j, -0.9612-0.0558j], dtype=torch.complex128)\n",
      "tensor([ 0.0030+0.1411j, -0.9612-0.0558j, -0.2388+0.0000j, -0.1070-0.0188j,\n",
      "        -0.1070+0.0188j, -0.7549+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0038+0.1409j, -0.9607-0.0545j], dtype=torch.complex128)\n",
      "tensor([ 0.0038+0.1409j, -0.9607-0.0545j, -0.2388+0.0000j, -0.1117-0.0197j,\n",
      "        -0.1117+0.0197j, -0.7591+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0046+0.1406j, -0.9603-0.0533j], dtype=torch.complex128)\n",
      "tensor([ 0.0046+0.1406j, -0.9603-0.0533j, -0.2388+0.0000j, -0.1161-0.0204j,\n",
      "        -0.1161+0.0204j, -0.7631+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0055+0.1404j, -0.9598-0.0522j], dtype=torch.complex128)\n",
      "tensor([ 0.0055+0.1404j, -0.9598-0.0522j, -0.2388+0.0000j, -0.1203-0.0212j,\n",
      "        -0.1203+0.0212j, -0.7668+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0065+0.1402j, -0.9594-0.0510j], dtype=torch.complex128)\n",
      "tensor([ 0.0065+0.1402j, -0.9594-0.0510j, -0.2388+0.0000j, -0.1241-0.0218j,\n",
      "        -0.1241+0.0218j, -0.7701+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0075+0.1400j, -0.9589-0.0500j], dtype=torch.complex128)\n",
      "tensor([ 0.0075+0.1400j, -0.9589-0.0500j, -0.2388+0.0000j, -0.1275-0.0224j,\n",
      "        -0.1275+0.0224j, -0.7732+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0085+0.1398j, -0.9585-0.0489j], dtype=torch.complex128)\n",
      "tensor([ 0.0085+0.1398j, -0.9585-0.0489j, -0.2388+0.0000j, -0.1306-0.0230j,\n",
      "        -0.1306+0.0230j, -0.7760+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0095+0.1396j, -0.9580-0.0479j], dtype=torch.complex128)\n",
      "tensor([ 0.0095+0.1396j, -0.9580-0.0479j, -0.2388+0.0000j, -0.1333-0.0235j,\n",
      "        -0.1333+0.0235j, -0.7783+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0106+0.1393j, -0.9575-0.0470j], dtype=torch.complex128)\n",
      "tensor([ 0.0106+0.1393j, -0.9575-0.0470j, -0.2388+0.0000j, -0.1355-0.0239j,\n",
      "        -0.1355+0.0239j, -0.7804+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0118+0.1391j, -0.9571-0.0460j], dtype=torch.complex128)\n",
      "tensor([ 0.0118+0.1391j, -0.9571-0.0460j, -0.2388+0.0000j, -0.1374-0.0242j,\n",
      "        -0.1374+0.0242j, -0.7820+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0129+0.1389j, -0.9566-0.0451j], dtype=torch.complex128)\n",
      "tensor([ 0.0129+0.1389j, -0.9566-0.0451j, -0.2388+0.0000j, -0.1388-0.0244j,\n",
      "        -0.1388+0.0244j, -0.7833+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0141+0.1387j, -0.9561-0.0442j], dtype=torch.complex128)\n",
      "tensor([ 0.0141+0.1387j, -0.9561-0.0442j, -0.2388+0.0000j, -0.1398-0.0246j,\n",
      "        -0.1398+0.0246j, -0.7841+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0152+0.1385j, -0.9557-0.0433j], dtype=torch.complex128)\n",
      "tensor([ 0.0152+0.1385j, -0.9557-0.0433j, -0.2388+0.0000j, -0.1403-0.0247j,\n",
      "        -0.1403+0.0247j, -0.7846+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0164+0.1383j, -0.9552-0.0424j], dtype=torch.complex128)\n",
      "tensor([ 0.0164+0.1383j, -0.9552-0.0424j, -0.2388+0.0000j, -0.1404-0.0247j,\n",
      "        -0.1404+0.0247j, -0.7847+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0176+0.1380j, -0.9547-0.0416j], dtype=torch.complex128)\n",
      "tensor([ 0.0176+0.1380j, -0.9547-0.0416j, -0.2388+0.0000j, -0.1400-0.0246j,\n",
      "        -0.1400+0.0246j, -0.7844+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0188+0.1378j, -0.9543-0.0407j], dtype=torch.complex128)\n",
      "tensor([ 0.0188+0.1378j, -0.9543-0.0407j, -0.2388+0.0000j, -0.1392-0.0245j,\n",
      "        -0.1392+0.0245j, -0.7837+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0200+0.1376j, -0.9538-0.0398j], dtype=torch.complex128)\n",
      "tensor([ 0.0200+0.1376j, -0.9538-0.0398j, -0.2388+0.0000j, -0.1380-0.0243j,\n",
      "        -0.1380+0.0243j, -0.7826+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0211+0.1374j, -0.9533-0.0389j], dtype=torch.complex128)\n",
      "tensor([ 0.0211+0.1374j, -0.9533-0.0389j, -0.2388+0.0000j, -0.1364-0.0240j,\n",
      "        -0.1364+0.0240j, -0.7811+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0222+0.1372j, -0.9529-0.0380j], dtype=torch.complex128)\n",
      "tensor([ 0.0222+0.1372j, -0.9529-0.0380j, -0.2388+0.0000j, -0.1344-0.0236j,\n",
      "        -0.1344+0.0236j, -0.7793+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0234+0.1370j, -0.9524-0.0370j], dtype=torch.complex128)\n",
      "tensor([ 0.0234+0.1370j, -0.9524-0.0370j, -0.2388+0.0000j, -0.1320-0.0232j,\n",
      "        -0.1320+0.0232j, -0.7772+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0244+0.1368j, -0.9519-0.0361j], dtype=torch.complex128)\n",
      "tensor([ 0.0244+0.1368j, -0.9519-0.0361j, -0.2388+0.0000j, -0.1292-0.0227j,\n",
      "        -0.1292+0.0227j, -0.7747+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0255+0.1366j, -0.9514-0.0351j], dtype=torch.complex128)\n",
      "tensor([ 0.0255+0.1366j, -0.9514-0.0351j, -0.2388+0.0000j, -0.1262-0.0222j,\n",
      "        -0.1262+0.0222j, -0.7720+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0265+0.1365j, -0.9509-0.0341j], dtype=torch.complex128)\n",
      "tensor([ 0.0265+0.1365j, -0.9509-0.0341j, -0.2388+0.0000j, -0.1228-0.0216j,\n",
      "        -0.1228+0.0216j, -0.7690+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0275+0.1363j, -0.9504-0.0330j], dtype=torch.complex128)\n",
      "tensor([ 0.0275+0.1363j, -0.9504-0.0330j, -0.2388+0.0000j, -0.1191-0.0210j,\n",
      "        -0.1191+0.0210j, -0.7657+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0284+0.1361j, -0.9499-0.0319j], dtype=torch.complex128)\n",
      "tensor([ 0.0284+0.1361j, -0.9499-0.0319j, -0.2388+0.0000j, -0.1151-0.0203j,\n",
      "        -0.1151+0.0203j, -0.7622+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0293+0.1359j, -0.9494-0.0308j], dtype=torch.complex128)\n",
      "tensor([ 0.0293+0.1359j, -0.9494-0.0308j, -0.2388+0.0000j, -0.1110-0.0195j,\n",
      "        -0.1110+0.0195j, -0.7585+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0301+0.1358j, -0.9489-0.0297j], dtype=torch.complex128)\n",
      "tensor([ 0.0301+0.1358j, -0.9489-0.0297j, -0.2388+0.0000j, -0.1066-0.0188j,\n",
      "        -0.1066+0.0188j, -0.7546+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0309+0.1356j, -0.9484-0.0285j], dtype=torch.complex128)\n",
      "tensor([ 0.0309+0.1356j, -0.9484-0.0285j, -0.2388+0.0000j, -0.1021-0.0180j,\n",
      "        -0.1021+0.0180j, -0.7506+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0316+0.1354j, -0.9479-0.0272j], dtype=torch.complex128)\n",
      "tensor([ 0.0316+0.1354j, -0.9479-0.0272j, -0.2388+0.0000j, -0.0974-0.0171j,\n",
      "        -0.0974+0.0171j, -0.7464+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0323+0.1353j, -0.9474-0.0259j], dtype=torch.complex128)\n",
      "tensor([ 0.0323+0.1353j, -0.9474-0.0259j, -0.2388+0.0000j, -0.0926-0.0163j,\n",
      "        -0.0926+0.0163j, -0.7421+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0329+0.1351j, -0.9468-0.0246j], dtype=torch.complex128)\n",
      "tensor([ 0.0329+0.1351j, -0.9468-0.0246j, -0.2388+0.0000j, -0.0878-0.0154j,\n",
      "        -0.0878+0.0154j, -0.7378+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0335+0.1350j, -0.9463-0.0232j], dtype=torch.complex128)\n",
      "tensor([ 0.0335+0.1350j, -0.9463-0.0232j, -0.2388+0.0000j, -0.0829-0.0146j,\n",
      "        -0.0829+0.0146j, -0.7334+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0340+0.1349j, -0.9458-0.0218j], dtype=torch.complex128)\n",
      "tensor([ 0.0340+0.1349j, -0.9458-0.0218j, -0.2388+0.0000j, -0.0779-0.0137j,\n",
      "        -0.0779+0.0137j, -0.7291+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0344+0.1347j, -0.9452-0.0203j], dtype=torch.complex128)\n",
      "tensor([ 0.0344+0.1347j, -0.9452-0.0203j, -0.2388+0.0000j, -0.0730-0.0128j,\n",
      "        -0.0730+0.0128j, -0.7247+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0348+0.1346j, -0.9447-0.0188j], dtype=torch.complex128)\n",
      "tensor([ 0.0348+0.1346j, -0.9447-0.0188j, -0.2388+0.0000j, -0.0681-0.0120j,\n",
      "        -0.0681+0.0120j, -0.7203+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0351+0.1345j, -0.9441-0.0172j], dtype=torch.complex128)\n",
      "tensor([ 0.0351+0.1345j, -0.9441-0.0172j, -0.2388+0.0000j, -0.0633-0.0111j,\n",
      "        -0.0633+0.0111j, -0.7160+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0354+0.1343j, -0.9436-0.0155j], dtype=torch.complex128)\n",
      "tensor([ 0.0354+0.1343j, -0.9436-0.0155j, -0.2388+0.0000j, -0.0585-0.0103j,\n",
      "        -0.0585+0.0103j, -0.7118+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0356+0.1342j, -0.9430-0.0139j], dtype=torch.complex128)\n",
      "tensor([ 0.0356+0.1342j, -0.9430-0.0139j, -0.2388+0.0000j, -0.0538-0.0095j,\n",
      "        -0.0538+0.0095j, -0.7076+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0358+0.1341j, -0.9424-0.0122j], dtype=torch.complex128)\n",
      "tensor([ 0.0358+0.1341j, -0.9424-0.0122j, -0.2388+0.0000j, -0.0493-0.0087j,\n",
      "        -0.0493+0.0087j, -0.7036+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0359+0.1340j, -0.9418-0.0104j], dtype=torch.complex128)\n",
      "tensor([ 0.0359+0.1340j, -0.9418-0.0104j, -0.2388+0.0000j, -0.0449-0.0079j,\n",
      "        -0.0449+0.0079j, -0.6996+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0360+0.1339j, -0.9413-0.0086j], dtype=torch.complex128)\n",
      "tensor([ 0.0360+0.1339j, -0.9413-0.0086j, -0.2388+0.0000j, -0.0407-0.0072j,\n",
      "        -0.0407+0.0072j, -0.6959+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0360+0.1338j, -0.9407-0.0067j], dtype=torch.complex128)\n",
      "tensor([ 0.0360+0.1338j, -0.9407-0.0067j, -0.2388+0.0000j, -0.0366-0.0064j,\n",
      "        -0.0366+0.0064j, -0.6922+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0359+0.1337j, -0.9401-0.0049j], dtype=torch.complex128)\n",
      "tensor([ 0.0359+0.1337j, -0.9401-0.0049j, -0.2388+0.0000j, -0.0327-0.0058j,\n",
      "        -0.0327+0.0058j, -0.6888+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0358+0.1336j, -0.9395-0.0029j], dtype=torch.complex128)\n",
      "tensor([ 0.0358+0.1336j, -0.9395-0.0029j, -0.2388+0.0000j, -0.0290-0.0051j,\n",
      "        -0.0290+0.0051j, -0.6855+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0357+0.1335j, -0.9388-0.0010j], dtype=torch.complex128)\n",
      "tensor([ 0.0357+0.1335j, -0.9388-0.0010j, -0.2388+0.0000j, -0.0255-0.0045j,\n",
      "        -0.0255+0.0045j, -0.6824+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0355+0.1334j, -0.9382+0.0010j], dtype=torch.complex128)\n",
      "tensor([ 0.0355+0.1334j, -0.9382+0.0010j, -0.2388+0.0000j, -0.0222-0.0039j,\n",
      "        -0.0222+0.0039j, -0.6794+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0353+0.1333j, -0.9376+0.0030j], dtype=torch.complex128)\n",
      "tensor([ 0.0353+0.1333j, -0.9376+0.0030j, -0.2388+0.0000j, -0.0191-0.0034j,\n",
      "        -0.0191+0.0034j, -0.6767+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0351+0.1333j, -0.9370+0.0051j], dtype=torch.complex128)\n",
      "tensor([ 0.0351+0.1333j, -0.9370+0.0051j, -0.2388+0.0000j, -0.0163-0.0029j,\n",
      "        -0.0163+0.0029j, -0.6741+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0348+0.1332j, -0.9363+0.0072j], dtype=torch.complex128)\n",
      "tensor([ 0.0348+0.1332j, -0.9363+0.0072j, -0.2388+0.0000j, -0.0136-0.0024j,\n",
      "        -0.0136+0.0024j, -0.6718+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0345+0.1331j, -0.9357+0.0093j], dtype=torch.complex128)\n",
      "tensor([ 0.0345+0.1331j, -0.9357+0.0093j, -0.2388+0.0000j, -0.0112-0.0020j,\n",
      "        -0.0112+0.0020j, -0.6696+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0341+0.1330j, -0.9350+0.0114j], dtype=torch.complex128)\n",
      "tensor([ 0.0341+0.1330j, -0.9350+0.0114j, -0.2388+0.0000j, -0.0090-0.0016j,\n",
      "        -0.0090+0.0016j, -0.6676+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0338+0.1329j, -0.9344+0.0135j], dtype=torch.complex128)\n",
      "tensor([ 0.0338+0.1329j, -0.9344+0.0135j, -0.2388+0.0000j, -0.0070-0.0012j,\n",
      "        -0.0070+0.0012j, -0.6659+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0334+0.1329j, -0.9337+0.0157j], dtype=torch.complex128)\n",
      "tensor([ 0.0334+0.1329j, -0.9337+0.0157j, -0.2388+0.0000j, -0.0052-0.0009j,\n",
      "        -0.0052+0.0009j, -0.6643+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0330+0.1328j, -0.9330+0.0179j], dtype=torch.complex128)\n",
      "tensor([ 0.0330+0.1328j, -0.9330+0.0179j, -0.2388+0.0000j, -0.0036-0.0006j,\n",
      "        -0.0036+0.0006j, -0.6629+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0326+0.1327j, -0.9323+0.0201j], dtype=torch.complex128)\n",
      "tensor([ 0.0326+0.1327j, -0.9323+0.0201j, -0.2388+0.0000j, -0.0022-0.0004j,\n",
      "        -0.0022+0.0004j, -0.6616+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0321+0.1327j, -0.9317+0.0223j], dtype=torch.complex128)\n",
      "tensor([ 0.0321+0.1327j, -0.9317+0.0223j, -0.2388+0.0000j, -0.0010-0.0002j,\n",
      "        -0.0010+0.0002j, -0.6606+0.0000j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n",
      "tensor([ 0.0317+0.1326j, -0.9310+0.0245j], dtype=torch.complex128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f259dcaf610>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 2\n",
    "states, H = read_data(\"data.hdf5\", 2, \"train\", i, i+1)\n",
    "H0 = H[0,0]\n",
    "psi0 = states[0,0]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "state_list = [psi0]\n",
    "with torch.no_grad():\n",
    "    for i in range(H.shape[1]-1):\n",
    "        input_tensor = torch.tensor(np.concatenate((state_list[-1].flatten(), H[0,i].flatten())), dtype=torch.complex128).to(device)\n",
    "        print(input_tensor)\n",
    "        output_tensor = model(input_tensor).cpu()\n",
    "        print(output_tensor)\n",
    "        state_list.append(np.array(output_tensor))\n",
    "\n",
    "\n",
    "prob0 = np.abs(states[0,:,0])**2\n",
    "t_end=10\n",
    "dt = 0.1\n",
    "t_list = np.arange(0, t_end+dt, dt)\n",
    "states_calc = [qt.Qobj(x) for x in state_list]\n",
    "prob0_calc = [np.abs(s[0][0][0])**2 for s in states_calc]\n",
    "# plt.plot(t_list, prob0, label=\"saved\")\n",
    "plt.plot(t_list, prob0_calc, label=\"calc\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
