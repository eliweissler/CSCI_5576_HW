{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Define the Control Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.tensordict import TensorDict, TensorDictBase\n",
    "from torch import nn\n",
    "\n",
    "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec\n",
    "from torchrl.envs import (\n",
    "    CatTensors,\n",
    "    EnvBase,\n",
    "    Transform,\n",
    "    TransformedEnv,\n",
    "    UnsqueezeTransform,\n",
    ")\n",
    "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
    "from torchrl.envs.utils import check_env_specs, step_mdp\n",
    "\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "print(device)\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "complex_type = torch.complex64\n",
    "PSI_0 = np.array([1, 0])\n",
    "PSI_0_tensor = torch.tensor(PSI_0, dtype=complex_type).to(device)\n",
    "PSI_F = np.array([0, 1])\n",
    "PSI_F_tensor = torch.tensor(PSI_F, dtype=complex_type).to(device)\n",
    "\n",
    "H0 = np.array([[1,  0],\n",
    "               [0, -1]])\n",
    "H0_tensor = torch.tensor(H0, dtype=complex_type).to(device)\n",
    "H1 = np.array([[0,  1],\n",
    "               [1,  0]])\n",
    "H1_tensor = torch.tensor(H1, dtype=complex_type).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Various Things We Need for TorchRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step function advances along the environment\n",
    "def _step(tensordict):\n",
    "\n",
    "    # Current quantum state and control value\n",
    "    psi_real, psi_im, control = tensordict[\"psi_real\"], tensordict[\"psi_imag\"], tensordict[\"action\"].squeeze(-1)\n",
    "    psi = psi_real + 1.0j*psi_im\n",
    "\n",
    "    # H0 and H1\n",
    "    H0 = tensordict[\"params\",\"H0\"]\n",
    "    H1 = tensordict[\"params\",\"H1\"]\n",
    "\n",
    "    # Timestep\n",
    "    dt = tensordict[\"params\", \"dt\"]\n",
    "\n",
    "    # Cost Function -- Fidelity with Final State\n",
    "    costs = torch.pow(torch.abs(torch.dot(psi, PSI_F_tensor)), 2)\n",
    "\n",
    "    # Propagate along the state\n",
    "    U = torch.linalg.matrix_exp(-1.0j*dt*(H0 + control*H1))\n",
    "    new_psi = U@psi\n",
    "\n",
    "    reward = -costs.view(*tensordict.shape, 1)\n",
    "    done = torch.zeros_like(reward, dtype=torch.bool)\n",
    "    out = TensorDict(\n",
    "        {\n",
    "            \"psi_real\": torch.real(new_psi),\n",
    "            \"psi_imag\": torch.imag(new_psi),\n",
    "            \"params\": tensordict[\"params\"],\n",
    "            \"reward\": reward,\n",
    "            \"done\": done,\n",
    "        },\n",
    "        tensordict.shape,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset function resets a run to the original starting state\n",
    "def _reset(self, tensordict):\n",
    "\n",
    "    if tensordict is None or tensordict.is_empty():\n",
    "        # if no tensordict is passed, we generate a single set of hyperparameters\n",
    "        # Otherwise, we assume that the input tensordict contains all the relevant\n",
    "        # parameters to get started.\n",
    "        tensordict = self.gen_params(batch_size=self.batch_size)\n",
    "\n",
    "    out = TensorDict(\n",
    "        {\n",
    "            \"psi_real\": torch.real(PSI_0_tensor),\n",
    "            \"psi_imag\": torch.imag(PSI_0_tensor),\n",
    "            \"params\": tensordict[\"params\"],\n",
    "        },\n",
    "        batch_size=tensordict.shape,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies the bounds of the environment\n",
    "def _make_spec(self, td_params):\n",
    "\n",
    "    # Under the hood, this will populate self.output_spec[\"observation\"]\n",
    "    self.observation_spec = CompositeSpec(\n",
    "        psi_real=BoundedTensorSpec(\n",
    "            low=-1,\n",
    "            high=1,\n",
    "            shape=(PSI_0.shape[0],),\n",
    "            dtype=torch.float32)\n",
    "        ,\n",
    "        psi_imag=BoundedTensorSpec(\n",
    "            low=-1,\n",
    "            high=1,\n",
    "            shape=(PSI_0.shape[0],),\n",
    "            dtype=torch.float32)\n",
    "        ,\n",
    "        # we need to add the \"params\" to the observation specs, as we want\n",
    "        # to pass it at each step during a rollout\n",
    "        params=make_composite_from_td(td_params[\"params\"]),\n",
    "        shape=(),\n",
    "    )\n",
    "    \n",
    "    # since the environment is stateless, we expect the previous output as input.\n",
    "    # For this, EnvBase expects some state_spec to be available\n",
    "    self.state_spec = self.observation_spec.clone()\n",
    "    # action-spec will be automatically wrapped in input_spec when\n",
    "    # `self.action_spec = spec` will be called supported\n",
    "    self.action_spec = BoundedTensorSpec(\n",
    "        low=-td_params[\"params\", \"max_amp\"],\n",
    "        high=td_params[\"params\", \"max_amp\"],\n",
    "        shape=(1,),\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "    self.reward_spec = UnboundedContinuousTensorSpec(shape=(*td_params.shape, 1))\n",
    "\n",
    "\n",
    "def make_composite_from_td(td):\n",
    "    # custom funtion to convert a tensordict in a similar spec structure\n",
    "    # of unbounded values.\n",
    "    composite = CompositeSpec(\n",
    "        {\n",
    "            key: make_composite_from_td(tensor)\n",
    "            if isinstance(tensor, TensorDictBase)\n",
    "            else UnboundedContinuousTensorSpec(\n",
    "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
    "            )\n",
    "            for key, tensor in td.items()\n",
    "        },\n",
    "        shape=td.shape,\n",
    "    )\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_seed(self, seed: Optional[int]):\n",
    "    rng = torch.manual_seed(seed)\n",
    "    self.rng = rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_params(dt=0.01, batch_size=None) -> TensorDictBase:\n",
    "    \"\"\"Returns a tensordict containing the physical parameters such as timestep and control stuff.\"\"\"\n",
    "    if batch_size is None:\n",
    "        batch_size = []\n",
    "    td = TensorDict(\n",
    "        {\n",
    "            \"params\": TensorDict(\n",
    "                {\n",
    "                    \"max_amp\": 1.0,\n",
    "                    \"dt\": dt,\n",
    "                    \"H0\": H0_tensor,\n",
    "                    \"H1\": H1_tensor  \n",
    "                },\n",
    "                [],\n",
    "            )\n",
    "        },\n",
    "        [],\n",
    "    )\n",
    "    if batch_size:\n",
    "        td = td.expand(batch_size).contiguous()\n",
    "    return td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumEnv(EnvBase):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 30,\n",
    "    }\n",
    "    batch_locked = False\n",
    "\n",
    "    def __init__(self, td_params=None, seed=None, device=\"cpu\"):\n",
    "        if td_params is None:\n",
    "            td_params = self.gen_params()\n",
    "\n",
    "        super().__init__(device=device, batch_size=[])\n",
    "        self._make_spec(td_params)\n",
    "        if seed is None:\n",
    "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
    "        self.set_seed(seed)\n",
    "\n",
    "    # Helpers: _make_step and gen_params\n",
    "    gen_params = staticmethod(gen_params)\n",
    "    _make_spec = _make_spec\n",
    "\n",
    "    # Mandatory methods: _step, _reset and _set_seed\n",
    "    _reset = _reset\n",
    "    _step = staticmethod(_step)\n",
    "    _set_seed = _set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "env = QuantumEnv()\n",
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_spec: CompositeSpec(\n",
      "    psi_real: BoundedTensorSpec(\n",
      "        shape=torch.Size([2]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    psi_imag: BoundedTensorSpec(\n",
      "        shape=torch.Size([2]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    params: CompositeSpec(\n",
      "        max_amp: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        dt: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        H0: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([2, 2]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.complex64,\n",
      "            domain=continuous),\n",
      "        H1: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([2, 2]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.complex64,\n",
      "            domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))\n",
      "state_spec: CompositeSpec(\n",
      "    psi_real: BoundedTensorSpec(\n",
      "        shape=torch.Size([2]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    psi_imag: BoundedTensorSpec(\n",
      "        shape=torch.Size([2]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    params: CompositeSpec(\n",
      "        max_amp: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        dt: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        H0: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([2, 2]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.complex64,\n",
      "            domain=continuous),\n",
      "        H1: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([2, 2]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.complex64,\n",
      "            domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))\n",
      "reward_spec: UnboundedContinuousTensorSpec(\n",
      "    shape=torch.Size([1]),\n",
      "    space=ContinuousBox(\n",
      "        low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "        high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "    device=cpu,\n",
      "    dtype=torch.float32,\n",
      "    domain=continuous)\n"
     ]
    }
   ],
   "source": [
    "print(\"observation_spec:\", env.observation_spec)\n",
    "print(\"state_spec:\", env.state_spec)\n",
    "print(\"reward_spec:\", env.reward_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset tensordict TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                H0: Tensor(shape=torch.Size([2, 2]), device=cpu, dtype=torch.complex64, is_shared=False),\n",
      "                H1: Tensor(shape=torch.Size([2, 2]), device=cpu, dtype=torch.complex64, is_shared=False),\n",
      "                dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_amp: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        psi_imag: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        psi_real: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.reset()\n",
    "print(\"reset tensordict\", td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random step tensordict TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        H0: Tensor(shape=torch.Size([2, 2]), device=cpu, dtype=torch.complex64, is_shared=False),\n",
      "                        H1: Tensor(shape=torch.Size([2, 2]), device=cpu, dtype=torch.complex64, is_shared=False),\n",
      "                        dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_amp: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                psi_imag: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                psi_real: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                H0: Tensor(shape=torch.Size([2, 2]), device=cpu, dtype=torch.complex64, is_shared=False),\n",
      "                H1: Tensor(shape=torch.Size([2, 2]), device=cpu, dtype=torch.complex64, is_shared=False),\n",
      "                dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_amp: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        psi_imag: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        psi_real: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.rand_step(td)\n",
    "print(\"random step tensordict\", td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (689547695.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 22\u001b[0;36m\u001b[0m\n\u001b[0;31m    def sample\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class quantum_env:\n",
    "\n",
    "    def __init__(self, psi0: qt.Qobj, H0: qt.Qobj, H1: qt.Qobj, psif: qt.Qobj, dt: float = 0.1, maxsteps: int = 100):\n",
    "\n",
    "        self.psi0 = psi0\n",
    "        self.H0 = H0\n",
    "        self.H1 = H1\n",
    "        self.psif = psif\n",
    "\n",
    "        self.psi0_arr = self.qObj_to_array(psi0)\n",
    "        self.H0_arr = self.qObj_to_array(H0)\n",
    "        self.H1_arr = self.qObj_to_array(H1)\n",
    "        self.psif_arr = self.qObj_to_array(psif)\n",
    "\n",
    "        self.action_space = quantum_action_space()\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        # Reset control input and state input\n",
    "        self.H1_coeff = 0\n",
    "        self.state = np.concatenate(self.H1_coeff*np.ones(1).flatten(), self.psi0_arr)\n",
    "        self.psi = self.psi0\n",
    "        info = {}\n",
    "\n",
    "        return self.psi0_arr, info\n",
    "    \n",
    "    def qObj_to_array(self, psi):\n",
    "        \n",
    "        as_arr = psi.full()\n",
    "        return np.concatenate((np.real(as_arr).flatten(), np.imag(as_arr).flatten()))\n",
    "    \n",
    "    def step(self, action):\n",
    "\n",
    "        self.H1_coeff += action\n",
    "        \n",
    "        res = qt.sesolve(self.H0 + self.H1_coeff*self.H1, self.psi, tlist=[0, self.dt])\n",
    "\n",
    "        self.psi = res.states[-1]\n",
    "        self.state = np.concatenate(self.H1_coeff, self.qObj_to_array(self.psi))\n",
    "\n",
    "        return\n",
    "\n",
    "class quantum_action_space:\n",
    "\n",
    "    def __init__(self, vmin = -0.1, vmax = 0.1, gradation=11):\n",
    "        self.vmin = vmin\n",
    "        self.vmax = vmax\n",
    "\n",
    "        self.actions = np.linspace(vmin, vmax, gradation)\n",
    "        self.n = self.actions.size\n",
    "\n",
    "    def sample(self):\n",
    "        return np.random.sample(self.actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\n",
      "\n",
      "Args:\n",
      "    action: The environment step action\n",
      "\n",
      "Returns:\n",
      "    The environment step ``(observation, reward, terminated, truncated, info)`` with `truncated=True`\n",
      "    if the number of steps elapsed >= max episode steps\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.conda/envs/torch/lib/python3.9/site-packages/gymnasium/wrappers/time_limit.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "env.step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.n\n",
    "env.reset()\n",
    "env.action_space.sample()\n",
    "env.step(action.item())\n",
    "observation, reward, terminated, truncated, _ = env.step(action.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
